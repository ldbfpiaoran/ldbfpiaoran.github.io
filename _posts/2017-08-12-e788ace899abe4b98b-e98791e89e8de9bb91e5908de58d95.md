---
id: 74
title: 爬虫之——金融黑名单
date: 2017-08-12T11:52:39+00:00
author: bfpiaoran
layout: post
guid: http://www.cuijianxiong.top/?p=74
permalink: /?p=74
categories:
  - 未分类
---
最进在看 python爬虫 正好最近金融闹得沸沸扬扬

<pre line="1">import pymysql
from urllib.request import urlopen
from bs4 import BeautifulSoup
 
def savep2p(name,inde,company,addrs,date,reason,url):
    try:
        conn = pymysql.connect(host='127.0.0.1',user='root',passwd='********',db='mysql',charset='utf8')
        conn = conn.cursor()
        conn.execute('use spider')
 
        savesql = 'insert into `problemp2p` (`name`,`inde`,`company`,`addrs`,`date`,`reason`,`url`) values (%s,%s,%s,%s,%s,%s,%s)'
        conn.execute(savesql,(name,inde,company,addrs,date,reason,url))
        conn.connection.commit()
    except:
        conn.close()
 
 
def get_url(url):
    response = urlopen(url)
    req = BeautifulSoup(response.read(),"lxml")
 
    p2plist = []
 
    result =  req.findAll('tr',{'class':'gra'})
    for i in result:
        #print(i)
        company = i.find('td',{'class':'company'}).get_text()
        name = i.a.get_text()
        addrs = i.find('td',{'class':'region'}).get_text()
        date = i.find('td',{'class':'problem_time'}).get_text()
        reason = i.find('td',{'class':'blacklist'}).get_text()
        url = i.find('td',{'class':'The_url'}).get_text()
 
        p2plist.append([name,company,addrs,date,reason,url])
 
    return p2plist
 
 
 
p2plist = get_url(url='http://wj.china.com.cn/Problem/lists.html')
 
#print(len(p2plist))
for i in p2plist:
    name = i[0]
    inde = '问题平台'
    company = i[1]
    addrs = i[2]
    date = i[3]
    reason = i[4]
    url = i[5]
    savep2p(name,inde,company,addrs,date,reason,url)
 
print('>>>>>>>>完成')
</pre>

存到spider下面的problemp2p表里面啦  
<img src="http://www.cuijianxiong.top/wp-content/uploads/2017/08/6-300x199.png" alt="" width="300" height="199" class="alignnone size-medium wp-image-75" srcset="http://www.cuijianxiong.top/wp-content/uploads/2017/08/6-300x199.png 300w, http://www.cuijianxiong.top/wp-content/uploads/2017/08/6-768x510.png 768w, http://www.cuijianxiong.top/wp-content/uploads/2017/08/6-1024x680.png 1024w, http://www.cuijianxiong.top/wp-content/uploads/2017/08/6-830x551.png 830w, http://www.cuijianxiong.top/wp-content/uploads/2017/08/6-230x153.png 230w, http://www.cuijianxiong.top/wp-content/uploads/2017/08/6-350x233.png 350w, http://www.cuijianxiong.top/wp-content/uploads/2017/08/6-480x319.png 480w, http://www.cuijianxiong.top/wp-content/uploads/2017/08/6.png 1207w" sizes="(max-width: 300px) 85vw, 300px" />  
爬完之后一看吓一跳3000多个  
数据不一定精确 ==